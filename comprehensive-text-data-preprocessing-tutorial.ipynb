{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swish9/comprehensive-text-data-preprocessing-tutorial?scriptVersionId=142185634\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Objective:\n\nThe primary objective of this notebook is to guide you through the essential steps of data preprocessing for CSV-based data. By the end of this tutorial, you should be proficient in importing data, exploring datasets, handling missing values, detecting and removing outliers, encoding categorical variables, and normalizing numeric features.","metadata":{}},{"cell_type":"markdown","source":"# Notebook Content\n\n\n1. **Importing Libraries (Practical):**\n   - Begin by importing the necessary Python libraries, such as Pandas, NumPy, and scikit-learn, for data preprocessing.\n\n2. **Importing Dataset (Practical):**\n   - Load your CSV-based dataset into a Pandas DataFrame for further analysis.\n\n3. **Exploring the Dataset (Practical):**\n   - Some of the Pandas functions used here to explore and understand the dataset are:\n     - `head()`: Display the first few rows of the DataFrame.\n     - `tail()`: Display the last few rows of the DataFrame.\n     - `duplicated()`: Identify duplicate rows in the DataFrame.\n     - `drop_duplicates()`: Remove duplicate rows.\n     - `describe()`: Provide summary statistics of numeric columns.\n     - `info()`: Display information about the DataFrame, including data types and missing values.\n\n4. **Handling Missing Values (Practical):**\n   - Address missing values in both categorical and numeric columns using appropriate techniques (e.g., imputation, removal).\n\n5. **Outlier Detection and Removal (Practical):**\n   - Identify and handle outliers in numeric columns using visualizations (e.g., box plots) and suitable methods (e.g., removing or transforming outliers).\n\n6. **Encoding Categorical Variables (Practical):**\n   - Encode categorical variables using one-hot encoding or label encoding, depending on the nature of the data.\n\n7. **Normalizing Numeric Features (Practical):**\n   - Normalize numeric features using techniques like Min-Max Scaling or Standardization.\n\n8. **Conclusion and Next Steps (Theory):**\n   - Summarize the key takeaways from the notebook.\n   - Suggest further preprocessing steps or additional analysis that can be performed on the cleaned dataset.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # Data manipulation\nimport numpy as np  # Numerical operations\nimport matplotlib.pyplot as plt  # Data visualization\nimport seaborn as sns  # Enhanced data visualization\nfrom sklearn.model_selection import train_test_split  # Data splitting\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler # Data preprocessing\nfrom sklearn.impute import SimpleImputer # Data preprocessing\nfrom scipy import stats # statistics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-07T03:52:54.78282Z","iopub.execute_input":"2023-09-07T03:52:54.783469Z","iopub.status.idle":"2023-09-07T03:52:54.790511Z","shell.execute_reply.started":"2023-09-07T03:52:54.783427Z","shell.execute_reply":"2023-09-07T03:52:54.789151Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/students-exam-scores/Expanded_data_with_more_features.csv') # Importing dataset ","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:54.792786Z","iopub.execute_input":"2023-09-07T03:52:54.793202Z","iopub.status.idle":"2023-09-07T03:52:54.890695Z","shell.execute_reply.started":"2023-09-07T03:52:54.793171Z","shell.execute_reply":"2023-09-07T03:52:54.889406Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Basic Dataset Exploration ","metadata":{}},{"cell_type":"code","source":"df.head()  # Display the first 5 rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:54.95254Z","iopub.execute_input":"2023-09-07T03:52:54.953031Z","iopub.status.idle":"2023-09-07T03:52:54.974059Z","shell.execute_reply.started":"2023-09-07T03:52:54.95299Z","shell.execute_reply":"2023-09-07T03:52:54.972708Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  Gender EthnicGroup          ParentEduc     LunchType TestPrep  \\\n0           0  female         NaN   bachelor's degree      standard     none   \n1           1  female     group C        some college      standard      NaN   \n2           2  female     group B     master's degree      standard     none   \n3           3    male     group A  associate's degree  free/reduced     none   \n4           4    male     group C        some college      standard     none   \n\n  ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings TransportMeans  \\\n0             married     regularly          yes         3.0     school_bus   \n1             married     sometimes          yes         0.0            NaN   \n2              single     sometimes          yes         4.0     school_bus   \n3             married         never           no         1.0            NaN   \n4             married     sometimes          yes         0.0     school_bus   \n\n  WklyStudyHours  MathScore  ReadingScore  WritingScore  \n0            < 5         71            71            74  \n1         5 - 10         69            90            88  \n2            < 5         87            93            91  \n3         5 - 10         45            56            42  \n4         5 - 10         76            78            75  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Gender</th>\n      <th>EthnicGroup</th>\n      <th>ParentEduc</th>\n      <th>LunchType</th>\n      <th>TestPrep</th>\n      <th>ParentMaritalStatus</th>\n      <th>PracticeSport</th>\n      <th>IsFirstChild</th>\n      <th>NrSiblings</th>\n      <th>TransportMeans</th>\n      <th>WklyStudyHours</th>\n      <th>MathScore</th>\n      <th>ReadingScore</th>\n      <th>WritingScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>bachelor's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>regularly</td>\n      <td>yes</td>\n      <td>3.0</td>\n      <td>school_bus</td>\n      <td>&lt; 5</td>\n      <td>71</td>\n      <td>71</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>NaN</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>5 - 10</td>\n      <td>69</td>\n      <td>90</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>female</td>\n      <td>group B</td>\n      <td>master's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>4.0</td>\n      <td>school_bus</td>\n      <td>&lt; 5</td>\n      <td>87</td>\n      <td>93</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>male</td>\n      <td>group A</td>\n      <td>associate's degree</td>\n      <td>free/reduced</td>\n      <td>none</td>\n      <td>married</td>\n      <td>never</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5 - 10</td>\n      <td>45</td>\n      <td>56</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>male</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>0.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>76</td>\n      <td>78</td>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.tail()  # Display the last 5 rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.062187Z","iopub.execute_input":"2023-09-07T03:52:55.062589Z","iopub.status.idle":"2023-09-07T03:52:55.082892Z","shell.execute_reply.started":"2023-09-07T03:52:55.062559Z","shell.execute_reply":"2023-09-07T03:52:55.081513Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0  Gender EthnicGroup          ParentEduc     LunchType  \\\n30636         816  female     group D         high school      standard   \n30637         890    male     group E         high school      standard   \n30638         911  female         NaN         high school  free/reduced   \n30639         934  female     group D  associate's degree      standard   \n30640         960    male     group B        some college      standard   \n\n        TestPrep ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings  \\\n30636       none              single     sometimes           no         2.0   \n30637       none              single     regularly           no         1.0   \n30638  completed             married     sometimes           no         1.0   \n30639  completed             married     regularly           no         3.0   \n30640       none             married         never           no         1.0   \n\n      TransportMeans WklyStudyHours  MathScore  ReadingScore  WritingScore  \n30636     school_bus         5 - 10         59            61            65  \n30637        private         5 - 10         58            53            51  \n30638        private         5 - 10         61            70            67  \n30639     school_bus         5 - 10         82            90            93  \n30640     school_bus         5 - 10         64            60            58  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Gender</th>\n      <th>EthnicGroup</th>\n      <th>ParentEduc</th>\n      <th>LunchType</th>\n      <th>TestPrep</th>\n      <th>ParentMaritalStatus</th>\n      <th>PracticeSport</th>\n      <th>IsFirstChild</th>\n      <th>NrSiblings</th>\n      <th>TransportMeans</th>\n      <th>WklyStudyHours</th>\n      <th>MathScore</th>\n      <th>ReadingScore</th>\n      <th>WritingScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30636</th>\n      <td>816</td>\n      <td>female</td>\n      <td>group D</td>\n      <td>high school</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>no</td>\n      <td>2.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>59</td>\n      <td>61</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>30637</th>\n      <td>890</td>\n      <td>male</td>\n      <td>group E</td>\n      <td>high school</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>regularly</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>private</td>\n      <td>5 - 10</td>\n      <td>58</td>\n      <td>53</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>30638</th>\n      <td>911</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>high school</td>\n      <td>free/reduced</td>\n      <td>completed</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>private</td>\n      <td>5 - 10</td>\n      <td>61</td>\n      <td>70</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>30639</th>\n      <td>934</td>\n      <td>female</td>\n      <td>group D</td>\n      <td>associate's degree</td>\n      <td>standard</td>\n      <td>completed</td>\n      <td>married</td>\n      <td>regularly</td>\n      <td>no</td>\n      <td>3.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>82</td>\n      <td>90</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>30640</th>\n      <td>960</td>\n      <td>male</td>\n      <td>group B</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>never</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>64</td>\n      <td>60</td>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.sample(n=5)  # Display the random n rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.212675Z","iopub.execute_input":"2023-09-07T03:52:55.213092Z","iopub.status.idle":"2023-09-07T03:52:55.23651Z","shell.execute_reply.started":"2023-09-07T03:52:55.213043Z","shell.execute_reply":"2023-09-07T03:52:55.235323Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0  Gender EthnicGroup         ParentEduc     LunchType  \\\n3421          616  female     group E        high school  free/reduced   \n18792         988    male     group C  bachelor's degree      standard   \n8833          352    male     group B    master's degree  free/reduced   \n20438         747    male     group E  bachelor's degree  free/reduced   \n25845         556  female     group C  bachelor's degree      standard   \n\n        TestPrep ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings  \\\n3421   completed              single     sometimes          yes         2.0   \n18792  completed              single     sometimes           no         3.0   \n8833        none             married     sometimes          yes         1.0   \n20438       none             married     regularly          yes         1.0   \n25845  completed             married     sometimes          yes         0.0   \n\n      TransportMeans WklyStudyHours  MathScore  ReadingScore  WritingScore  \n3421      school_bus            < 5         53            67            60  \n18792        private            < 5         59            67            65  \n8833         private            < 5         57            50            57  \n20438     school_bus         5 - 10         48            46            45  \n25845     school_bus         5 - 10         71            77            76  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Gender</th>\n      <th>EthnicGroup</th>\n      <th>ParentEduc</th>\n      <th>LunchType</th>\n      <th>TestPrep</th>\n      <th>ParentMaritalStatus</th>\n      <th>PracticeSport</th>\n      <th>IsFirstChild</th>\n      <th>NrSiblings</th>\n      <th>TransportMeans</th>\n      <th>WklyStudyHours</th>\n      <th>MathScore</th>\n      <th>ReadingScore</th>\n      <th>WritingScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3421</th>\n      <td>616</td>\n      <td>female</td>\n      <td>group E</td>\n      <td>high school</td>\n      <td>free/reduced</td>\n      <td>completed</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>2.0</td>\n      <td>school_bus</td>\n      <td>&lt; 5</td>\n      <td>53</td>\n      <td>67</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>18792</th>\n      <td>988</td>\n      <td>male</td>\n      <td>group C</td>\n      <td>bachelor's degree</td>\n      <td>standard</td>\n      <td>completed</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>no</td>\n      <td>3.0</td>\n      <td>private</td>\n      <td>&lt; 5</td>\n      <td>59</td>\n      <td>67</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>8833</th>\n      <td>352</td>\n      <td>male</td>\n      <td>group B</td>\n      <td>master's degree</td>\n      <td>free/reduced</td>\n      <td>none</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>private</td>\n      <td>&lt; 5</td>\n      <td>57</td>\n      <td>50</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>20438</th>\n      <td>747</td>\n      <td>male</td>\n      <td>group E</td>\n      <td>bachelor's degree</td>\n      <td>free/reduced</td>\n      <td>none</td>\n      <td>married</td>\n      <td>regularly</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>48</td>\n      <td>46</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>25845</th>\n      <td>556</td>\n      <td>female</td>\n      <td>group C</td>\n      <td>bachelor's degree</td>\n      <td>standard</td>\n      <td>completed</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>0.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>71</td>\n      <td>77</td>\n      <td>76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"num_rows, num_columns = df.shape\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.238551Z","iopub.execute_input":"2023-09-07T03:52:55.238982Z","iopub.status.idle":"2023-09-07T03:52:55.246787Z","shell.execute_reply.started":"2023-09-07T03:52:55.238946Z","shell.execute_reply":"2023-09-07T03:52:55.245552Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(30641, 15)"},"metadata":{}}]},{"cell_type":"code","source":"df.columns # Display column name ","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.248369Z","iopub.execute_input":"2023-09-07T03:52:55.248754Z","iopub.status.idle":"2023-09-07T03:52:55.259879Z","shell.execute_reply.started":"2023-09-07T03:52:55.248722Z","shell.execute_reply":"2023-09-07T03:52:55.258934Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'Gender', 'EthnicGroup', 'ParentEduc', 'LunchType',\n       'TestPrep', 'ParentMaritalStatus', 'PracticeSport', 'IsFirstChild',\n       'NrSiblings', 'TransportMeans', 'WklyStudyHours', 'MathScore',\n       'ReadingScore', 'WritingScore'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"One-line explanation for each column in the provided DataFrame:\n\n1. **'Unnamed: 0'**: Likely an index or identifier column.\n2. **'Gender'**: Gender of the student (e.g., male or female).\n3. **'EthnicGroup'**: Ethnic group or background of the student.\n4. **'ParentEduc'**: Education level of the student's parent(s).\n5. **'LunchType'**: Type of lunch the student receives (e.g., free/reduced or standard).\n6. **'TestPrep'**: Whether the student completed test preparation (e.g., yes or no).\n7. **'ParentMaritalStatus'**: Marital status of the student's parent(s).\n8. **'PracticeSport'**: Whether the student practices a sport (e.g., yes or no).\n9. **'IsFirstChild'**: Whether the student is the first child in the family (e.g., yes or no).\n10. **'NrSiblings'**: Number of siblings the student has.\n11. **'TransportMeans'**: Means of transportation to school (e.g., bus, car, etc.).\n12. **'WklyStudyHours'**: Number of weekly study hours.\n13. **'MathScore'**: Score in the math exam.\n14. **'ReadingScore'**: Score in the reading exam.\n15. **'WritingScore'**: Score in the writing exam.","metadata":{}},{"cell_type":"code","source":"df.describe(include='all').T # statistics","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.372131Z","iopub.execute_input":"2023-09-07T03:52:55.372958Z","iopub.status.idle":"2023-09-07T03:52:55.497592Z","shell.execute_reply.started":"2023-09-07T03:52:55.37292Z","shell.execute_reply":"2023-09-07T03:52:55.496291Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                       count unique           top   freq        mean  \\\nUnnamed: 0           30641.0    NaN           NaN    NaN  499.556607   \nGender                 30641      2        female  15424         NaN   \nEthnicGroup            28801      5       group C   9212         NaN   \nParentEduc             28796      6  some college   6633         NaN   \nLunchType              30641      2      standard  19905         NaN   \nTestPrep               28811      2          none  18856         NaN   \nParentMaritalStatus    29451      4       married  16844         NaN   \nPracticeSport          30010      3     sometimes  15213         NaN   \nIsFirstChild           29737      2           yes  19082         NaN   \nNrSiblings           29069.0    NaN           NaN    NaN    2.145894   \nTransportMeans         27507      2    school_bus  16145         NaN   \nWklyStudyHours         29686      3        5 - 10  16246         NaN   \nMathScore            30641.0    NaN           NaN    NaN   66.558402   \nReadingScore         30641.0    NaN           NaN    NaN   69.377533   \nWritingScore         30641.0    NaN           NaN    NaN   68.418622   \n\n                            std   min    25%    50%    75%    max  \nUnnamed: 0           288.747894   0.0  249.0  500.0  750.0  999.0  \nGender                      NaN   NaN    NaN    NaN    NaN    NaN  \nEthnicGroup                 NaN   NaN    NaN    NaN    NaN    NaN  \nParentEduc                  NaN   NaN    NaN    NaN    NaN    NaN  \nLunchType                   NaN   NaN    NaN    NaN    NaN    NaN  \nTestPrep                    NaN   NaN    NaN    NaN    NaN    NaN  \nParentMaritalStatus         NaN   NaN    NaN    NaN    NaN    NaN  \nPracticeSport               NaN   NaN    NaN    NaN    NaN    NaN  \nIsFirstChild                NaN   NaN    NaN    NaN    NaN    NaN  \nNrSiblings             1.458242   0.0    1.0    2.0    3.0    7.0  \nTransportMeans              NaN   NaN    NaN    NaN    NaN    NaN  \nWklyStudyHours              NaN   NaN    NaN    NaN    NaN    NaN  \nMathScore             15.361616   0.0   56.0   67.0   78.0  100.0  \nReadingScore          14.758952  10.0   59.0   70.0   80.0  100.0  \nWritingScore          15.443525   4.0   58.0   69.0   79.0  100.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Unnamed: 0</th>\n      <td>30641.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>499.556607</td>\n      <td>288.747894</td>\n      <td>0.0</td>\n      <td>249.0</td>\n      <td>500.0</td>\n      <td>750.0</td>\n      <td>999.0</td>\n    </tr>\n    <tr>\n      <th>Gender</th>\n      <td>30641</td>\n      <td>2</td>\n      <td>female</td>\n      <td>15424</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>EthnicGroup</th>\n      <td>28801</td>\n      <td>5</td>\n      <td>group C</td>\n      <td>9212</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ParentEduc</th>\n      <td>28796</td>\n      <td>6</td>\n      <td>some college</td>\n      <td>6633</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>LunchType</th>\n      <td>30641</td>\n      <td>2</td>\n      <td>standard</td>\n      <td>19905</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>TestPrep</th>\n      <td>28811</td>\n      <td>2</td>\n      <td>none</td>\n      <td>18856</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ParentMaritalStatus</th>\n      <td>29451</td>\n      <td>4</td>\n      <td>married</td>\n      <td>16844</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>PracticeSport</th>\n      <td>30010</td>\n      <td>3</td>\n      <td>sometimes</td>\n      <td>15213</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>IsFirstChild</th>\n      <td>29737</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>19082</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>NrSiblings</th>\n      <td>29069.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.145894</td>\n      <td>1.458242</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>TransportMeans</th>\n      <td>27507</td>\n      <td>2</td>\n      <td>school_bus</td>\n      <td>16145</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>WklyStudyHours</th>\n      <td>29686</td>\n      <td>3</td>\n      <td>5 - 10</td>\n      <td>16246</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>MathScore</th>\n      <td>30641.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>66.558402</td>\n      <td>15.361616</td>\n      <td>0.0</td>\n      <td>56.0</td>\n      <td>67.0</td>\n      <td>78.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>ReadingScore</th>\n      <td>30641.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>69.377533</td>\n      <td>14.758952</td>\n      <td>10.0</td>\n      <td>59.0</td>\n      <td>70.0</td>\n      <td>80.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>WritingScore</th>\n      <td>30641.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>68.418622</td>\n      <td>15.443525</td>\n      <td>4.0</td>\n      <td>58.0</td>\n      <td>69.0</td>\n      <td>79.0</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.dtypes # Display Datatypes of columns","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.499959Z","iopub.execute_input":"2023-09-07T03:52:55.500358Z","iopub.status.idle":"2023-09-07T03:52:55.509839Z","shell.execute_reply.started":"2023-09-07T03:52:55.500326Z","shell.execute_reply":"2023-09-07T03:52:55.50854Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0               int64\nGender                  object\nEthnicGroup             object\nParentEduc              object\nLunchType               object\nTestPrep                object\nParentMaritalStatus     object\nPracticeSport           object\nIsFirstChild            object\nNrSiblings             float64\nTransportMeans          object\nWklyStudyHours          object\nMathScore                int64\nReadingScore             int64\nWritingScore             int64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df.count() # Display non-null values","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.511261Z","iopub.execute_input":"2023-09-07T03:52:55.512261Z","iopub.status.idle":"2023-09-07T03:52:55.557986Z","shell.execute_reply.started":"2023-09-07T03:52:55.512215Z","shell.execute_reply":"2023-09-07T03:52:55.556557Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0             30641\nGender                 30641\nEthnicGroup            28801\nParentEduc             28796\nLunchType              30641\nTestPrep               28811\nParentMaritalStatus    29451\nPracticeSport          30010\nIsFirstChild           29737\nNrSiblings             29069\nTransportMeans         27507\nWklyStudyHours         29686\nMathScore              30641\nReadingScore           30641\nWritingScore           30641\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df[df.isna()] # Display null rows","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.56003Z","iopub.execute_input":"2023-09-07T03:52:55.560455Z","iopub.status.idle":"2023-09-07T03:52:55.631414Z","shell.execute_reply.started":"2023-09-07T03:52:55.560421Z","shell.execute_reply":"2023-09-07T03:52:55.629983Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0 Gender EthnicGroup ParentEduc LunchType TestPrep  \\\n0             NaN    NaN         NaN        NaN       NaN      NaN   \n1             NaN    NaN         NaN        NaN       NaN      NaN   \n2             NaN    NaN         NaN        NaN       NaN      NaN   \n3             NaN    NaN         NaN        NaN       NaN      NaN   \n4             NaN    NaN         NaN        NaN       NaN      NaN   \n...           ...    ...         ...        ...       ...      ...   \n30636         NaN    NaN         NaN        NaN       NaN      NaN   \n30637         NaN    NaN         NaN        NaN       NaN      NaN   \n30638         NaN    NaN         NaN        NaN       NaN      NaN   \n30639         NaN    NaN         NaN        NaN       NaN      NaN   \n30640         NaN    NaN         NaN        NaN       NaN      NaN   \n\n      ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings  \\\n0                     NaN           NaN          NaN         NaN   \n1                     NaN           NaN          NaN         NaN   \n2                     NaN           NaN          NaN         NaN   \n3                     NaN           NaN          NaN         NaN   \n4                     NaN           NaN          NaN         NaN   \n...                   ...           ...          ...         ...   \n30636                 NaN           NaN          NaN         NaN   \n30637                 NaN           NaN          NaN         NaN   \n30638                 NaN           NaN          NaN         NaN   \n30639                 NaN           NaN          NaN         NaN   \n30640                 NaN           NaN          NaN         NaN   \n\n      TransportMeans WklyStudyHours  MathScore  ReadingScore  WritingScore  \n0                NaN            NaN        NaN           NaN           NaN  \n1                NaN            NaN        NaN           NaN           NaN  \n2                NaN            NaN        NaN           NaN           NaN  \n3                NaN            NaN        NaN           NaN           NaN  \n4                NaN            NaN        NaN           NaN           NaN  \n...              ...            ...        ...           ...           ...  \n30636            NaN            NaN        NaN           NaN           NaN  \n30637            NaN            NaN        NaN           NaN           NaN  \n30638            NaN            NaN        NaN           NaN           NaN  \n30639            NaN            NaN        NaN           NaN           NaN  \n30640            NaN            NaN        NaN           NaN           NaN  \n\n[30641 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Gender</th>\n      <th>EthnicGroup</th>\n      <th>ParentEduc</th>\n      <th>LunchType</th>\n      <th>TestPrep</th>\n      <th>ParentMaritalStatus</th>\n      <th>PracticeSport</th>\n      <th>IsFirstChild</th>\n      <th>NrSiblings</th>\n      <th>TransportMeans</th>\n      <th>WklyStudyHours</th>\n      <th>MathScore</th>\n      <th>ReadingScore</th>\n      <th>WritingScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30636</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30637</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30638</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30639</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30640</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>30641 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum() # Display null values","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.6329Z","iopub.execute_input":"2023-09-07T03:52:55.633291Z","iopub.status.idle":"2023-09-07T03:52:55.676513Z","shell.execute_reply.started":"2023-09-07T03:52:55.633258Z","shell.execute_reply":"2023-09-07T03:52:55.67505Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                0\nGender                    0\nEthnicGroup            1840\nParentEduc             1845\nLunchType                 0\nTestPrep               1830\nParentMaritalStatus    1190\nPracticeSport           631\nIsFirstChild            904\nNrSiblings             1572\nTransportMeans         3134\nWklyStudyHours          955\nMathScore                 0\nReadingScore              0\nWritingScore              0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.nunique() # Display Count of Unique Values in a Columns","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.679445Z","iopub.execute_input":"2023-09-07T03:52:55.679845Z","iopub.status.idle":"2023-09-07T03:52:55.718347Z","shell.execute_reply.started":"2023-09-07T03:52:55.67981Z","shell.execute_reply":"2023-09-07T03:52:55.716995Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0             1000\nGender                    2\nEthnicGroup               5\nParentEduc                6\nLunchType                 2\nTestPrep                  2\nParentMaritalStatus       4\nPracticeSport             3\nIsFirstChild              2\nNrSiblings                8\nTransportMeans            2\nWklyStudyHours            3\nMathScore                95\nReadingScore             90\nWritingScore             93\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.duplicated().sum() # Display Count of Duplicated Values in a Datafram","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.719424Z","iopub.execute_input":"2023-09-07T03:52:55.719746Z","iopub.status.idle":"2023-09-07T03:52:55.783136Z","shell.execute_reply.started":"2023-09-07T03:52:55.719718Z","shell.execute_reply":"2023-09-07T03:52:55.782033Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df.drop_duplicates() # Dropping Duplicates","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.785933Z","iopub.execute_input":"2023-09-07T03:52:55.786617Z","iopub.status.idle":"2023-09-07T03:52:55.86824Z","shell.execute_reply.started":"2023-09-07T03:52:55.786572Z","shell.execute_reply":"2023-09-07T03:52:55.867073Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0  Gender EthnicGroup          ParentEduc     LunchType  \\\n0               0  female         NaN   bachelor's degree      standard   \n1               1  female     group C        some college      standard   \n2               2  female     group B     master's degree      standard   \n3               3    male     group A  associate's degree  free/reduced   \n4               4    male     group C        some college      standard   \n...           ...     ...         ...                 ...           ...   \n30636         816  female     group D         high school      standard   \n30637         890    male     group E         high school      standard   \n30638         911  female         NaN         high school  free/reduced   \n30639         934  female     group D  associate's degree      standard   \n30640         960    male     group B        some college      standard   \n\n        TestPrep ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings  \\\n0           none             married     regularly          yes         3.0   \n1            NaN             married     sometimes          yes         0.0   \n2           none              single     sometimes          yes         4.0   \n3           none             married         never           no         1.0   \n4           none             married     sometimes          yes         0.0   \n...          ...                 ...           ...          ...         ...   \n30636       none              single     sometimes           no         2.0   \n30637       none              single     regularly           no         1.0   \n30638  completed             married     sometimes           no         1.0   \n30639  completed             married     regularly           no         3.0   \n30640       none             married         never           no         1.0   \n\n      TransportMeans WklyStudyHours  MathScore  ReadingScore  WritingScore  \n0         school_bus            < 5         71            71            74  \n1                NaN         5 - 10         69            90            88  \n2         school_bus            < 5         87            93            91  \n3                NaN         5 - 10         45            56            42  \n4         school_bus         5 - 10         76            78            75  \n...              ...            ...        ...           ...           ...  \n30636     school_bus         5 - 10         59            61            65  \n30637        private         5 - 10         58            53            51  \n30638        private         5 - 10         61            70            67  \n30639     school_bus         5 - 10         82            90            93  \n30640     school_bus         5 - 10         64            60            58  \n\n[30641 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Gender</th>\n      <th>EthnicGroup</th>\n      <th>ParentEduc</th>\n      <th>LunchType</th>\n      <th>TestPrep</th>\n      <th>ParentMaritalStatus</th>\n      <th>PracticeSport</th>\n      <th>IsFirstChild</th>\n      <th>NrSiblings</th>\n      <th>TransportMeans</th>\n      <th>WklyStudyHours</th>\n      <th>MathScore</th>\n      <th>ReadingScore</th>\n      <th>WritingScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>bachelor's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>regularly</td>\n      <td>yes</td>\n      <td>3.0</td>\n      <td>school_bus</td>\n      <td>&lt; 5</td>\n      <td>71</td>\n      <td>71</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>NaN</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>5 - 10</td>\n      <td>69</td>\n      <td>90</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>female</td>\n      <td>group B</td>\n      <td>master's degree</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>4.0</td>\n      <td>school_bus</td>\n      <td>&lt; 5</td>\n      <td>87</td>\n      <td>93</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>male</td>\n      <td>group A</td>\n      <td>associate's degree</td>\n      <td>free/reduced</td>\n      <td>none</td>\n      <td>married</td>\n      <td>never</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5 - 10</td>\n      <td>45</td>\n      <td>56</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>male</td>\n      <td>group C</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>yes</td>\n      <td>0.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>76</td>\n      <td>78</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30636</th>\n      <td>816</td>\n      <td>female</td>\n      <td>group D</td>\n      <td>high school</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>sometimes</td>\n      <td>no</td>\n      <td>2.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>59</td>\n      <td>61</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>30637</th>\n      <td>890</td>\n      <td>male</td>\n      <td>group E</td>\n      <td>high school</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>single</td>\n      <td>regularly</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>private</td>\n      <td>5 - 10</td>\n      <td>58</td>\n      <td>53</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>30638</th>\n      <td>911</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>high school</td>\n      <td>free/reduced</td>\n      <td>completed</td>\n      <td>married</td>\n      <td>sometimes</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>private</td>\n      <td>5 - 10</td>\n      <td>61</td>\n      <td>70</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>30639</th>\n      <td>934</td>\n      <td>female</td>\n      <td>group D</td>\n      <td>associate's degree</td>\n      <td>standard</td>\n      <td>completed</td>\n      <td>married</td>\n      <td>regularly</td>\n      <td>no</td>\n      <td>3.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>82</td>\n      <td>90</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>30640</th>\n      <td>960</td>\n      <td>male</td>\n      <td>group B</td>\n      <td>some college</td>\n      <td>standard</td>\n      <td>none</td>\n      <td>married</td>\n      <td>never</td>\n      <td>no</td>\n      <td>1.0</td>\n      <td>school_bus</td>\n      <td>5 - 10</td>\n      <td>64</td>\n      <td>60</td>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n<p>30641 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info() # Display info about the Datafrme","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:55.869968Z","iopub.execute_input":"2023-09-07T03:52:55.870345Z","iopub.status.idle":"2023-09-07T03:52:55.915619Z","shell.execute_reply.started":"2023-09-07T03:52:55.870314Z","shell.execute_reply":"2023-09-07T03:52:55.91438Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30641 entries, 0 to 30640\nData columns (total 15 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Unnamed: 0           30641 non-null  int64  \n 1   Gender               30641 non-null  object \n 2   EthnicGroup          28801 non-null  object \n 3   ParentEduc           28796 non-null  object \n 4   LunchType            30641 non-null  object \n 5   TestPrep             28811 non-null  object \n 6   ParentMaritalStatus  29451 non-null  object \n 7   PracticeSport        30010 non-null  object \n 8   IsFirstChild         29737 non-null  object \n 9   NrSiblings           29069 non-null  float64\n 10  TransportMeans       27507 non-null  object \n 11  WklyStudyHours       29686 non-null  object \n 12  MathScore            30641 non-null  int64  \n 13  ReadingScore         30641 non-null  int64  \n 14  WritingScore         30641 non-null  int64  \ndtypes: float64(1), int64(4), object(10)\nmemory usage: 3.5+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"categorical_cols = df.select_dtypes(include=['object']).columns # Selecting categorical columns \nnumeric_cols = df.select_dtypes(include=[np.number]).columns # Selecting numerical columns ","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.623318Z","iopub.status.idle":"2023-09-07T03:52:57.624298Z","shell.execute_reply.started":"2023-09-07T03:52:57.624053Z","shell.execute_reply":"2023-09-07T03:52:57.624089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Categorical Missing Values**","metadata":{}},{"cell_type":"code","source":"categorical_imputer = SimpleImputer(strategy='most_frequent')","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.625266Z","iopub.status.idle":"2023-09-07T03:52:57.625855Z","shell.execute_reply.started":"2023-09-07T03:52:57.625646Z","shell.execute_reply":"2023-09-07T03:52:57.625668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SimpleImputer(strategy='most_frequent')** is a data preprocessing technique that replaces missing values in a dataset with the most frequent value (mode) for each respective column. It's often used for categorical data where missing values are replaced with the category that occurs most frequently in that column.","metadata":{}},{"cell_type":"code","source":"df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.627108Z","iopub.status.idle":"2023-09-07T03:52:57.627911Z","shell.execute_reply.started":"2023-09-07T03:52:57.627714Z","shell.execute_reply":"2023-09-07T03:52:57.627734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[categorical_cols].isnull().sum() # Varifying if categorical missing values are handled well","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.62902Z","iopub.status.idle":"2023-09-07T03:52:57.62993Z","shell.execute_reply.started":"2023-09-07T03:52:57.629718Z","shell.execute_reply":"2023-09-07T03:52:57.629739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Numerical Missing Values**","metadata":{}},{"cell_type":"code","source":"# This is standard approach but it will also outliers i.e. extremely outperforming values which kinda will add noise to data\n# numeric_imputer = SimpleImputer(strategy='mean')\n# data[numeric_cols] = numeric_imputer.fit_transform(data[numeric_cols])\n\n# So we'll be using Trimmed mean approach for handling numeric values \n\nfor col in numeric_cols:\n    # Calculate the trimmed mean (5%)\n    trimmed_mean = stats.trim_mean(df[col].dropna(), proportiontocut=0.05)\n    df[col].fillna(trimmed_mean, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.631119Z","iopub.status.idle":"2023-09-07T03:52:57.631905Z","shell.execute_reply.started":"2023-09-07T03:52:57.631711Z","shell.execute_reply":"2023-09-07T03:52:57.631732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using a trimmed mean (e.g., 5%) instead of a simple imputer mean strategy is preferred when you want to:\n\n1. **Reduce Outlier Influence:** Mitigate the impact of outliers or extreme values on the central tendency measure.\n   \n2. **Preserve Data Distribution:** Retain more information about the underlying data distribution.\n\n3. **Fine-Tune Trimming:** Have control over the percentage of data points to trim, allowing customization based on your dataset characteristics.","metadata":{}},{"cell_type":"code","source":"df[numeric_cols].isnull().sum() # Varifying if categorical missing values are handled well","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.633307Z","iopub.status.idle":"2023-09-07T03:52:57.633697Z","shell.execute_reply.started":"2023-09-07T03:52:57.633501Z","shell.execute_reply":"2023-09-07T03:52:57.633528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoding Categorical features**","metadata":{}},{"cell_type":"code","source":"# Initialize the OneHotEncoder with drop='first'\nencoder = OneHotEncoder(drop='first', sparse_output=False)\n# ‘first’ : drop the first category in each feature.\n# sparse_output: Will return sparse matrix if set True else will return an array.","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.634807Z","iopub.status.idle":"2023-09-07T03:52:57.635257Z","shell.execute_reply.started":"2023-09-07T03:52:57.635011Z","shell.execute_reply":"2023-09-07T03:52:57.635042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-Hot Encoding (OHE) with \"drop first\" is a variation of OHE where one category is dropped to avoid multicollinearity, which can occur when you have binary columns that are perfectly correlated. \n\nHere's how it works:\n\n- If you have a categorical feature with `n` categories, OHE without \"drop first\" would create `n` binary columns.\n\n- OHE with \"drop first\" creates only `n - 1` binary columns. It drops one category (usually the first) and represents it indirectly through the absence of all the other categories being 1.\n\n**Example:**\n\nLet's say you have a categorical feature \"Color\" with three categories: Red, Blue, and Green.\n\nWithout \"drop first,\" OHE creates three binary columns:\n\n- Red: 1 if the color is Red, 0 otherwise.\n- Blue: 1 if the color is Blue, 0 otherwise.\n- Green: 1 if the color is Green, 0 otherwise.\n\nWith \"drop first,\" OHE creates two binary columns:\n\n- Blue: 1 if the color is Blue, 0 otherwise.\n- Green: 1 if the color is Green, 0 otherwise.\n\nIn this example, the absence of both Blue and Green being 1 implies that the color is Red. So, you can represent all three categories with two binary columns instead of three, which can be useful for some machine learning algorithms.","metadata":{}},{"cell_type":"code","source":"# Fit and transform the encoder on categorical columns\nencoded_cols = encoder.fit_transform(df[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.636454Z","iopub.status.idle":"2023-09-07T03:52:57.63683Z","shell.execute_reply.started":"2023-09-07T03:52:57.636646Z","shell.execute_reply":"2023-09-07T03:52:57.636664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame from the encoded columns\nencoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n#  concatenates encoded feature name and category with feature + \"_\" + str(category).E.g. feature X with values 1, 6, 7 create feature names X_1, X_6, X_7","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.638383Z","iopub.status.idle":"2023-09-07T03:52:57.638777Z","shell.execute_reply.started":"2023-09-07T03:52:57.638588Z","shell.execute_reply":"2023-09-07T03:52:57.638607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the original categorical columns from the original DataFrame\ndf.drop(categorical_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.640618Z","iopub.status.idle":"2023-09-07T03:52:57.640975Z","shell.execute_reply.started":"2023-09-07T03:52:57.640799Z","shell.execute_reply":"2023-09-07T03:52:57.640816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the original DataFrame with the encoded DataFrame\ndf = pd.concat([df, encoded_df], axis=1)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.642525Z","iopub.status.idle":"2023-09-07T03:52:57.642887Z","shell.execute_reply.started":"2023-09-07T03:52:57.642708Z","shell.execute_reply":"2023-09-07T03:52:57.642725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes # Verifying the encoding procedure ","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.64414Z","iopub.status.idle":"2023-09-07T03:52:57.644524Z","shell.execute_reply.started":"2023-09-07T03:52:57.644318Z","shell.execute_reply":"2023-09-07T03:52:57.644335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Outlier Detection**","metadata":{}},{"cell_type":"markdown","source":"**Outliers** are data points that significantly differ from the rest of the observations in a dataset. They can be exceptionally high or low values compared to the majority of data points.\n\n**Why Remove Outliers:**\n\nOutliers can distort statistical analyses and models, leading to biased results.\nThey can skew the mean and standard deviation, affecting the overall data distribution.\nSome machine learning algorithms are sensitive to outliers, impacting their performance.\nOutliers can represent data errors or anomalies that may not reflect the true underlying patterns.","metadata":{}},{"cell_type":"code","source":"df.mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.645791Z","iopub.status.idle":"2023-09-07T03:52:57.646174Z","shell.execute_reply.started":"2023-09-07T03:52:57.645969Z","shell.execute_reply":"2023-09-07T03:52:57.645986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.subplot(1, 2, 1)\nsns.boxplot(data=df, orient=\"h\")","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.647441Z","iopub.status.idle":"2023-09-07T03:52:57.647796Z","shell.execute_reply.started":"2023-09-07T03:52:57.647619Z","shell.execute_reply":"2023-09-07T03:52:57.647636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subplots for violin plots\nplt.figure(figsize=(16, 10))\nplt.subplot(1, 2, 2)\nsns.violinplot(data=df, orient=\"h\", inner=\"quart\") ","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.649208Z","iopub.status.idle":"2023-09-07T03:52:57.651948Z","shell.execute_reply.started":"2023-09-07T03:52:57.651642Z","shell.execute_reply":"2023-09-07T03:52:57.65167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 2 # The threshold variable is set to a value that determines how far away from the mean is considered an outlier\ndf = df[(np.abs(df - df.mean()) < threshold * df.std()).all(axis=1)] # (x - mean) / std represents the z-score or standard score of a data point x in a dataset.","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.653281Z","iopub.status.idle":"2023-09-07T03:52:57.654006Z","shell.execute_reply.started":"2023-09-07T03:52:57.653709Z","shell.execute_reply":"2023-09-07T03:52:57.653735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.655661Z","iopub.status.idle":"2023-09-07T03:52:57.656232Z","shell.execute_reply.started":"2023-09-07T03:52:57.655927Z","shell.execute_reply":"2023-09-07T03:52:57.655964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalizing Data**","metadata":{}},{"cell_type":"code","source":"# Initialize the MinMaxScaler\nMMS = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.658028Z","iopub.status.idle":"2023-09-07T03:52:57.6588Z","shell.execute_reply.started":"2023-09-07T03:52:57.658589Z","shell.execute_reply":"2023-09-07T03:52:57.65861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MinMaxScaler** is a data preprocessing technique used to transform numeric data, typically features, into a specific range, usually between 0 and 1. It scales and shifts the original values so that they fall within this specified range while maintaining their relative relationships.\n\nHere's a brief explanation:\n\n- **Scaling Range**: MinMaxScaler scales the original data within a specified range, often between 0 and 1, but you can adjust this range as needed.\n\n- **Formula**: It uses the following formula to transform each data point `X` to its scaled counterpart `X_scaled`:\n\n  ```\n  X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n  X_scaled = X_std * (max - min) + min\n  \n  ```\n\n\n  Where `X_min` is the minimum value in the original dataset, and `X_max` is the maximum value.\n\n- **Normalization**: MinMax scaling is a form of normalization that makes the data more suitable for machine learning algorithms that are sensitive to the scale of the features. It preserves the relationships between data points and maintains the data's distribution.\n\n**Example**:\n\nSuppose you have a dataset with a feature \"Age,\" and the ages range from 20 to 60. By applying MinMaxScaler with a range of 0 to 1:\n\n- Age 20 would be scaled to 0.\n- Age 60 would be scaled to 1.\n- Ages in between 20 and 60 would be scaled proportionally between 0 and 1, preserving their relative positions.\n\nMinMaxScaler is commonly used when you want to ensure that different features have the same scale, especially in machine learning algorithms like support vector machines (SVM) or k-nearest neighbors (KNN), where the scale of features can impact the results.","metadata":{}},{"cell_type":"code","source":"# Fit and transform the scaler on numeric columns\ndf[numeric_cols] = MMS.fit_transform(df[numeric_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.660143Z","iopub.status.idle":"2023-09-07T03:52:57.66101Z","shell.execute_reply.started":"2023-09-07T03:52:57.660806Z","shell.execute_reply":"2023-09-07T03:52:57.660826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.662743Z","iopub.status.idle":"2023-09-07T03:52:57.663327Z","shell.execute_reply.started":"2023-09-07T03:52:57.66302Z","shell.execute_reply":"2023-09-07T03:52:57.663045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all').T # vering the normalization","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.665029Z","iopub.status.idle":"2023-09-07T03:52:57.665608Z","shell.execute_reply.started":"2023-09-07T03:52:57.665331Z","shell.execute_reply":"2023-09-07T03:52:57.665358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2023-09-07T03:52:57.667393Z","iopub.status.idle":"2023-09-07T03:52:57.667912Z","shell.execute_reply.started":"2023-09-07T03:52:57.667646Z","shell.execute_reply":"2023-09-07T03:52:57.667671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\n**In conclusion, this comprehensive CSV data preprocessing tutorial has covered essential steps to prepare your dataset for analysis, visualization, and machine learning applications.** ","metadata":{}}]}